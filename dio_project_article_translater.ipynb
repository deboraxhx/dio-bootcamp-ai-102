{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6_fxQthSaDP6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for script_or_style in soup([\"script\", \"style\"]):\n",
        "            script_or_style.decompose()\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        # Limpar texto\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        text_clean = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "        return text_clean\n",
        "    else:\n",
        "        print(f\"Failed to fecth the URL, Status does: {response.status_code}\" )\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lh6FNzJTjdIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
        "\n",
        "client = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-4o-mini\",\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    azure_endpoint = \"https://oai-dio-project.openai.azure.com/\",\n",
        "    api_key = \"SECRETS\",\n",
        "    max_retries = 0\n",
        ")\n",
        "\n",
        "def translate_article(text, lang):\n",
        "    messages = [\n",
        "        (\"system\", \"Você atua como tradutor de textos\"),\n",
        "        (\"user\", f\"Traduta o {text} para o idioma {lang} e responda em markdown\")\n",
        "        ]\n",
        "\n",
        "    response = client.invoke(messages)\n",
        "    print(response.content)\n",
        "    return response.content\n"
      ],
      "metadata": {
        "id": "2iJUcBNyb8-r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo\"\n",
        "\n",
        "\n",
        "translate_article(extract_text_from_url(url), \"portugues\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E4YlBCPzeUlS",
        "outputId": "be8771e1-4907-4358-a2e6-cbd119643dad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Azure Open AI em VNet\n",
            "\n",
            "## Resumo\n",
            "Os modelos GPT estão hospedados em vários provedores de serviços no momento, e o Microsoft Azure é um deles. Apesar de os modelos em si serem os mesmos, existem muitas diferenças, incluindo: custos, funcionalidades, tipos de modelos e versões, geolocalização, suporte à segurança, etc. Um dos aspectos mais importantes ao usá-los em um ambiente corporativo é, claro, a segurança.\n",
            "\n",
            "## Segurança com Azure Open AI\n",
            "Ao utilizar os recursos de segurança de rede do Azure com o Azure Open AI, os clientes podem consumir o serviço do Open AI a partir e dentro da VNet, portanto, nenhuma informação está fluindo para o público. \n",
            "\n",
            "### Implantação de Exemplo\n",
            "O repositório de exemplo do Azure fornece arquivos bicep de exemplo para implantar o Azure Open AI em um ambiente VNet.\n",
            "\n",
            "**GitHub:** openai-enterprise-iac\n",
            "\n",
            "Os recursos principais que o bicep utiliza são:\n",
            "- Integração VNet para Web App\n",
            "- Endpoint Privado para Azure Open AI\n",
            "- Endpoint Privado para Pesquisa Cognitiva\n",
            "- Zona DNS Privada\n",
            "\n",
            "Usando esses recursos, todo o tráfego de saída do Web App é roteado apenas dentro da VNet, e todos os nomes são resolvidos em endereços IP privados. O Open AI e a Pesquisa Cognitiva desativam o endereço IP público, portanto, não há mais um endpoint de interface pública disponível.\n",
            "\n",
            "## Implantar\n",
            "O arquivo bicep implantará os seguintes recursos do Azure. Vamos implantar e confirmar como funciona. \n",
            "Criei um grupo de recursos na região East US para meu próprio teste.\n",
            "\n",
            "```bash\n",
            "git clone https://github.com/Azure-Samples/openai-enterprise-iac\n",
            "cd openai-enterprise-iac\n",
            "az group create -n openaitest -l eastus\n",
            "az deployment group create -g openaitest -f ./infra/main.bicep\n",
            "```\n",
            "\n",
            "Assim que eu executo o comando acima, vejo que a implantação começou. Espere até que a implantação complete.\n",
            "\n",
            "## Testar\n",
            "Vamos ver se a implantação foi bem-sucedida.\n",
            "\n",
            "### Azure Open AI\n",
            "Primeiro, tentaremos o acesso público. Eu consegui criar uma implantação sem nenhum problema. Mas quando eu tentei a partir do playground de chat no meu portal do Azure, vi o seguinte erro. \n",
            "\n",
            "E quanto ao acesso via API Web? A partir de uma ferramenta avançada do App Service, eu entrei na sessão Bash e primeiro fiz um ping na URL do serviço. Eu vi que o endereço IP privado atribuído ao Endpoint Privado foi retornado. Depois, usei o comando `curl` para enviar uma solicitação ao endpoint.\n",
            "\n",
            "## Comentários\n",
            "(0 Inscritos) \n",
            "\n",
            "---\n",
            "\n",
            "Essa tradução apresenta um resumo da postagem do Kenichiro Nakamura sobre o uso do Azure Open AI em uma rede virtual (VNet), enfatizando a segurança e os detalhes técnicos da implementação.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Azure Open AI em VNet\\n\\n## Resumo\\nOs modelos GPT estão hospedados em vários provedores de serviços no momento, e o Microsoft Azure é um deles. Apesar de os modelos em si serem os mesmos, existem muitas diferenças, incluindo: custos, funcionalidades, tipos de modelos e versões, geolocalização, suporte à segurança, etc. Um dos aspectos mais importantes ao usá-los em um ambiente corporativo é, claro, a segurança.\\n\\n## Segurança com Azure Open AI\\nAo utilizar os recursos de segurança de rede do Azure com o Azure Open AI, os clientes podem consumir o serviço do Open AI a partir e dentro da VNet, portanto, nenhuma informação está fluindo para o público. \\n\\n### Implantação de Exemplo\\nO repositório de exemplo do Azure fornece arquivos bicep de exemplo para implantar o Azure Open AI em um ambiente VNet.\\n\\n**GitHub:** openai-enterprise-iac\\n\\nOs recursos principais que o bicep utiliza são:\\n- Integração VNet para Web App\\n- Endpoint Privado para Azure Open AI\\n- Endpoint Privado para Pesquisa Cognitiva\\n- Zona DNS Privada\\n\\nUsando esses recursos, todo o tráfego de saída do Web App é roteado apenas dentro da VNet, e todos os nomes são resolvidos em endereços IP privados. O Open AI e a Pesquisa Cognitiva desativam o endereço IP público, portanto, não há mais um endpoint de interface pública disponível.\\n\\n## Implantar\\nO arquivo bicep implantará os seguintes recursos do Azure. Vamos implantar e confirmar como funciona. \\nCriei um grupo de recursos na região East US para meu próprio teste.\\n\\n```bash\\ngit clone https://github.com/Azure-Samples/openai-enterprise-iac\\ncd openai-enterprise-iac\\naz group create -n openaitest -l eastus\\naz deployment group create -g openaitest -f ./infra/main.bicep\\n```\\n\\nAssim que eu executo o comando acima, vejo que a implantação começou. Espere até que a implantação complete.\\n\\n## Testar\\nVamos ver se a implantação foi bem-sucedida.\\n\\n### Azure Open AI\\nPrimeiro, tentaremos o acesso público. Eu consegui criar uma implantação sem nenhum problema. Mas quando eu tentei a partir do playground de chat no meu portal do Azure, vi o seguinte erro. \\n\\nE quanto ao acesso via API Web? A partir de uma ferramenta avançada do App Service, eu entrei na sessão Bash e primeiro fiz um ping na URL do serviço. Eu vi que o endereço IP privado atribuído ao Endpoint Privado foi retornado. Depois, usei o comando `curl` para enviar uma solicitação ao endpoint.\\n\\n## Comentários\\n(0 Inscritos) \\n\\n---\\n\\nEssa tradução apresenta um resumo da postagem do Kenichiro Nakamura sobre o uso do Azure Open AI em uma rede virtual (VNet), enfatizando a segurança e os detalhes técnicos da implementação.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8juSpDN_hJGP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}